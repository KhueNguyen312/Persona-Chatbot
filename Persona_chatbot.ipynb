{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Persona chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11luyZ0Mcc2p6l2nIFE31uE6nmm0yQXDd",
      "authorship_tag": "ABX9TyOkicDXiON+6La3VuyY07l4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyaoranClone/Persona-Chatbot/blob/master/Persona_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cRfdffuypIT"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4kE9OVyDnyD",
        "outputId": "bc4795ae-63f8-4c91-d9fb-9135d04aa6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#install Apex\n",
        "%%writefile setup.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "cd apex\n",
        "pip install -v --no-cache-dir ./\n",
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTRc_k_5w4wg"
      },
      "source": [
        "import json\n",
        "import time\n",
        "import os\n",
        "from itertools import chain\n",
        "from argparse import ArgumentParser\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import (AdamW, OpenAIGPTDoubleHeadsModel, OpenAIGPTTokenizer,\n",
        "                                 GPT2DoubleHeadsModel, GPT2Tokenizer, WEIGHTS_NAME, CONFIG_NAME)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlSBJz8H2IA_"
      },
      "source": [
        "#According to Huggingface Convai tutorial\n",
        "SPECIAL_TOKENS = [\"<bos>\", \"<eos>\", \"<speaker1>\", \"<speaker2>\", \"<pad>\"]\n",
        "ATTR_TO_SPECIAL_TOKEN = {'bos_token': '<bos>', 'eos_token': '<eos>', 'pad_token': '<pad>',\n",
        "                         'additional_special_tokens': ['<speaker1>', '<speaker2>']}\n",
        "MODEL_INPUTS = [\"input_ids\", \"mc_token_ids\", \"lm_labels\", \"mc_labels\", \"token_type_ids\"]\n",
        "PADDED_INPUTS = [\"input_ids\", \"lm_labels\", \"token_type_ids\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVWOi74ZzaPK"
      },
      "source": [
        "#define hyperparameters\n",
        "params = {}\n",
        "params[\"model_checkpoint\"]  = 'gpt2'\n",
        "params[\"device\"]  = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "params[\"lr\"]  = 6.25e-5\n",
        "params[\"num_candidates\"]  = 2\n",
        "params[\"num_history\"]  = 2 #Number of previous exchanges to keep in history\n",
        "params[\"fp16_training\"] = \"O1\" #Set to O0, O1, O2 or O3 for fp16 training\n",
        "params[\"url\"]  = \"https://s3.amazonaws.com/datasets.huggingface.co/personachat/personachat_self_original.json\"\n",
        "params[\"local_path\"] = \"/content/drive/My Drive/Colab Notebooks/Dataset/personachat_self_original.json\"\n",
        "params[\"dataset_cache_path\"] = \"/content/drive/My Drive/Colab Notebooks/Dataset/dataset_cache/persona_cache.bin_GPT2Tokenizer\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KpGazIhUBqU"
      },
      "source": [
        "class FacebookPersonaDataset():\n",
        "  \"\"\"\n",
        "    Concatenate context segments in a single sequence [[bos+persona], [history], [reply+eos]]\n",
        "    Tokenize and convert them to tensor\n",
        "    \n",
        "  \"\"\"\n",
        "  def __init__(self,url,cache_path,tokenizer = ''):\n",
        "    self.file_path = url\n",
        "    self.tokenizer = tokenizer\n",
        "    self.cache_path = cache_path\n",
        "\n",
        "  def _load_dataset(self):\n",
        "    #self.cache_path = self.cache_path + '_' + type(self.tokenizer).__name__  # To avoid using GPT cache for GPT-2 and vice-versa\n",
        "    if self.cache_path and os.path.isfile(self.cache_path):\n",
        "      #load tokenized dataset\n",
        "      dataset = torch.load(self.cache_path)\n",
        "      print(\"dataset loaded\")\n",
        "    else:\n",
        "      with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        dataset = json.loads(f.read())\n",
        "      \n",
        "      def tokenize(obj):\n",
        "        if isinstance(obj,str):\n",
        "          return self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(obj))\n",
        "        if isinstance(obj,dict):\n",
        "          return dict((n, tokenize(o)) for n, o in obj.items())\n",
        "        return list(tokenize(o) for o in obj)\n",
        "      dataset = tokenize(dataset)\n",
        "      torch.save(dataset,self.cache_path)\n",
        "    return dataset\n",
        "\n",
        "  def _pad_dataset(self,dataset, padding=0):\n",
        "    \"\"\" Pad the dataset. This could be optimized by defining a Dataset class and padding at the batch level, but this is simpler. \"\"\"\n",
        "    max_l = max(len(x) for x in dataset[\"input_ids\"])\n",
        "    for name in PADDED_INPUTS:\n",
        "        dataset[name] = [x + [padding if name != \"lm_labels\" else -100] * (max_l - len(x)) for x in dataset[name]]\n",
        "    return dataset\n",
        "\n",
        "  def _build_input(self,persona,history,reply,lm_labels = False,with_eos = True):\n",
        "    \"\"\" Build a sequence of input from 3 segments: persona, history and last reply. \"\"\"\n",
        "    bos, eos, speaker1, speaker2 = self.tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS[:-1])\n",
        "    #bos, eos, speaker1, speaker2 = \"<bos>\", \"<eos>\", \"<speaker1>\", \"<speaker2>\"\n",
        "    #sequence = [[bos] + list(persona) + [\"his\"] + history + [\"rep\"] + [reply]]\n",
        "    sequence = [[bos] + list(chain(*persona))] + history + [reply + ([eos] if with_eos else [])] #add bos, eos\n",
        "    sequence = [sequence[0]] + [[speaker2 if (len(sequence)-i) % 2 else speaker1] + s for i, s in enumerate(sequence[1:])] #add speaker1, speaker2\n",
        "    #after concat: [[bos+persona], [history], [reply+eos]]\n",
        "    instance = {}\n",
        "    instance[\"input_ids\"] = list(chain(*sequence))\n",
        "    #segment\n",
        "    instance[\"token_type_ids\"] = [speaker2 if i % 2 else speaker1 for i, s in enumerate(sequence) for _ in s]\n",
        "    #position\n",
        "    instance[\"mc_token_ids\"] = len(instance[\"input_ids\"]) - 1\n",
        "    #language model labels is used to calculate lm_loss\n",
        "    instance[\"lm_labels\"] = [-100] * len(instance[\"input_ids\"]) #labels set to -100 are ignored (masked)\n",
        "    if lm_labels:\n",
        "        instance[\"lm_labels\"] = ([-100] * sum(len(s) for s in sequence[:-1])) + [-100] + sequence[-1][1:]\n",
        "    return instance\n",
        "\n",
        "  def get_data_loaders(self):\n",
        "    personachat_dataset = self._load_dataset()\n",
        "    datasets = {\"train\": defaultdict(list), \"valid\": defaultdict(list)}\n",
        "    for name,dataset in personachat_dataset.items():\n",
        "      num_candidates = len(dataset[0][\"utterances\"][0][\"candidates\"]) #num_candidates are same for all dialoges\n",
        "      if params[\"num_candidates\"] > 0 and name == 'train':\n",
        "        num_candidates =  min(num_candidates ,params[\"num_candidates\"])\n",
        "      for dialoge in dataset:\n",
        "        persona = dialoge[\"personality\"].copy()\n",
        "        for utterance in dialoge[\"utterances\"]:\n",
        "          history = utterance[\"history\"][-(2*params[\"num_history\"]+1):]\n",
        "          for j, candidate in enumerate(utterance[\"candidates\"][-num_candidates:]):\n",
        "            #The last candidate is a ground truth reponse.\n",
        "            lm_labels = bool(j==num_candidates-1)\n",
        "            instance = self._build_input(persona,history,candidate,lm_labels)\n",
        "            for input_name,data in instance.items():\n",
        "              datasets[name][input_name].append(data) #datasets['train']['input_ids'] of [[c1 in u1],[c2 in u1],..,[c1 in u 7][c2 in u7]]\n",
        "          datasets[name][\"mc_labels\"].append(num_candidates - 1) #\n",
        "          datasets[name][\"n_candidates\"] = num_candidates\n",
        "\n",
        "    #pad input and convert to tensor\n",
        "    print(\"pad input and convert to tensor\")\n",
        "    tensor_datasets = {\"train\": [], \"valid\": []}\n",
        "    for dataset_name, dataset in datasets.items():\n",
        "      dataset =  self._pad_dataset(dataset, padding=self.tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS[-1]))\n",
        "      for input_name in MODEL_INPUTS:\n",
        "        tensor =  torch.tensor(dataset[input_name])\n",
        "        if input_name != \"mc_labels\":\n",
        "          tensor = tensor.view((-1, datasets[dataset_name][\"n_candidates\"]) + tensor.shape[1:])\n",
        "        tensor_datasets[dataset_name].append(tensor)\n",
        "\n",
        "    train_dataset, valid_dataset = TensorDataset(*tensor_datasets[\"train\"]), TensorDataset(*tensor_datasets[\"valid\"])\n",
        "    return train_dataset, valid_dataset "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BhPSl9HHCzB"
      },
      "source": [
        "persona_dataset = FacebookPersonaDataset(params[\"local_path\"],params[\"dataset_cache_path\"],tokenizer)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vxH-bjByRfJ",
        "outputId": "132eda15-dc79-4c7f-c542-fb36ea78e522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#datasets = persona_dataset._load_dataset()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tekpUzGE-lEZ",
        "outputId": "8b816498-056b-49e1-d1f6-f0e7daaa8c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_dataset, valid_dataset = persona_dataset.get_data_loaders() "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset loaded\n",
            "pad input and convert to tensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY8Pw_6oSWsz",
        "outputId": "724a4cee-4237-46c0-a4a4-6f3fc1639f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataset.tensors[0].shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([131438, 2, 280])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0WetWt820zx"
      },
      "source": [
        "def add_special_token(model,tokenizer):\n",
        "  origin_num_tokens = len(tokenizer.encoder)\n",
        "  num_special_tokens = tokenizer.add_special_tokens(ATTR_TO_SPECIAL_TOKEN)\n",
        "  if num_special_tokens > 0:\n",
        "        model.resize_token_embeddings(new_num_tokens=origin_num_tokens + num_special_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDzKolTBxBuE",
        "outputId": "240b0e42-f2e1-4c5f-fb23-c03a79244f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = GPT2DoubleHeadsModel.from_pretrained(params[\"model_checkpoint\"])\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(params[\"model_checkpoint\"])\n",
        "model.to(params[\"device\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2DoubleHeadsModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'multiple_choice_head.summary.weight', 'lm_head.weight', 'multiple_choice_head.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2DoubleHeadsModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "  (multiple_choice_head): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=1, bias=True)\n",
              "    (activation): Identity()\n",
              "    (first_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (last_dropout): Identity()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcS_NATZ11B-"
      },
      "source": [
        "add_special_token(model,tokenizer)\n",
        "optimizer = AdamW(model.parameters(), lr=params[\"lr\"] , correct_bias=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vh7caeyG2oh"
      },
      "source": [
        "if params[\"fp16_training\"]:\n",
        "  from apex import amp\n",
        "  # Allow Amp to perform casts as required by the opt_level \n",
        "  model,optimizer = amp.initialize(model,optimizer,opt_level=params[\"fp16_training\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk3sxWcaRjNx"
      },
      "source": [
        "def get_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u08d7LQuJ2r2"
      },
      "source": [
        "def train():\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  start_time = time.time()\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOZjHfN9K07L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}